{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIpREY9bj3gO"
      },
      "source": [
        "#Project Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAnvL_0sj6pv"
      },
      "source": [
        "# **The Data**\n",
        "\n",
        "\n",
        "**Features - Spectral Energy Distribution**\n",
        "\n",
        "A spectral energy distribution (SED) shows how the energy output of a galaxy is distributed across the electromagnetix spectrum. This tells us how bright a galaxy is at each particular wavelength.\n",
        "\n",
        "Each component of a galaxy leaves a specific imprint on the SED.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Targets**\n",
        "\n",
        "\n",
        "Each of these targets impacts the SED differently\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   **Age**\n",
        "2. **Stellar Mass**\n",
        "3. **Dust (A_v)**\n",
        "\n",
        "When dust is present, some of the ultraviolet and blue optical light is absorbed and re-emitted in the infared. The \"spikes\" in the SED are caused by polycyclic aromatic hydrocarbons (PAHs), which give important clues about the structures of dust in a galaxy.\n",
        "\n",
        "Dust can cause ambiguity when predicting the age of a galaxy. A young but dusty galaxy appears red, but so does an old and clear galaxy. Both of these have significant infared outputs.\n",
        "\n",
        "\n",
        "Each of these targets impacts the SED differently.\n",
        "\n",
        "\n",
        "**The Goal**\n",
        "\n",
        "Use various machine learning algorithms to predict each target based on the spectral data. Diagnose, optimize, and repeat!\n",
        "\n",
        "Conclude with challenges and results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8ZXgF9JW706"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3Fbl_SsXIU7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, cross_validate\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import preprocessing, decomposition\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "import sklearn\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moWZC44vXQ71"
      },
      "outputs": [],
      "source": [
        "properties = pd.read_csv('https://raw.githubusercontent.com/hannahestauss/Happiness-Analysis-Vis/main/GalaxyProperties.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JThQKGYeXbfE"
      },
      "outputs": [],
      "source": [
        "spectra = pd.read_csv('https://raw.githubusercontent.com/hannahestauss/Happiness-Analysis-Vis/main/spectra.csv', delimiter=\" \", header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG9oLOuFXEdZ"
      },
      "source": [
        "#Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7058MV9CXl3d"
      },
      "outputs": [],
      "source": [
        "properties.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAkcaddjcGXt"
      },
      "outputs": [],
      "source": [
        "properties.drop(['Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EH7scKTYX-s"
      },
      "outputs": [],
      "source": [
        "spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7upn13ZbviA"
      },
      "outputs": [],
      "source": [
        "fig = properties.hist(figsize=(12,12))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0O-F6vSPstB"
      },
      "outputs": [],
      "source": [
        "# Assuming 'properties' is your DataFrame with multiple variables including 'Mass'\n",
        "# Extract the columns you want to normalize (excluding 'Mass')\n",
        "columns_to_normalize = properties.columns.difference(['Log10(Mass/Mass_Sun)', 'Dust attenuation value'])\n",
        "\n",
        "# Normalize the selected columns using Min-Max scaling\n",
        "properties_normalized = (properties[columns_to_normalize] - properties[columns_to_normalize].min()) / (properties[columns_to_normalize].max() - properties[columns_to_normalize].min())\n",
        "\n",
        "# Add the 'Mass' column back to the normalized DataFrame\n",
        "properties_normalized['Log10(Mass/Mass_Sun)'] = properties['Log10(Mass/Mass_Sun)']\n",
        "properties_normalized['Dust attenuation value'] = properties['Dust attenuation value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA7AsE0qRjk5"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import boxcox\n",
        "dust_attenuation = properties['Dust attenuation value'].values\n",
        "\n",
        "transformed_data, lambda_value = boxcox(dust_attenuation)\n",
        "properties['Dust attenuation value'] = transformed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-IE1QrWNkAB"
      },
      "outputs": [],
      "source": [
        "#properties['Dust attenuation value'] = boxcox(properties['Dust attenuation value'])\n",
        "properties['Tau (Gyr)'] = np.log(properties['Tau (Gyr)'])\n",
        "properties['Age (Gyr)'] = np.log(properties['Age (Gyr)'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBaQW3zhOOka"
      },
      "outputs": [],
      "source": [
        "fig = properties.hist(figsize=(12,12))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCnoA_OCcxvT"
      },
      "source": [
        "From these, I predict that dust and Tau will likely be the most difficult properties to predict. The only normally distributed value is Solar Mass, while the age graph seems to be only the right half of a normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5LWmdmJdR1H"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "Age = properties['Age (Gyr)']\n",
        "TAU = properties['Tau (Gyr)']\n",
        "DAT = properties['Dust attenuation value']\n",
        "Mass = properties['Log10(Mass/Mass_Sun)']\n",
        "targets = [Age, TAU, DAT, Mass]\n",
        "for x in targets:\n",
        "  x = le.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVvhx67ch5w9"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scalespec = scaler.fit_transform(spectra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnehxLQ3ns3w"
      },
      "outputs": [],
      "source": [
        "scalespecdf = pd.DataFrame(scalespec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNn8z_DSmk9_"
      },
      "source": [
        "#Learning Curve Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95bW49WZmp_g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzfKVwY6KQyb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=5,\n",
        "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), scoring = 'neg_mean_squared_error', scale = False):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"# of training examples\",fontsize = 14)\n",
        "\n",
        "    plt.ylabel(\"Score\",fontsize = 14)\n",
        "\n",
        "    if (scale == True):\n",
        "        scaler = sklearn.preprocessing.StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = scoring)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "#   plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"b\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\",\n",
        "             label=\"Training score from CV\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Test score from CV\")\n",
        "\n",
        "    plt.legend(loc=\"best\",fontsize = 12)\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MlgCkVNmp_i"
      },
      "outputs": [],
      "source": [
        "def accplot_learning_curve(estimator, title, X, y, ylim=None, cv=5,\n",
        "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), scoring = 'accuracy', scale = False):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"# of training examples\",fontsize = 14)\n",
        "\n",
        "    plt.ylabel(\"Score\",fontsize = 14)\n",
        "\n",
        "    if (scale == True):\n",
        "        scaler = sklearn.preprocessing.StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = scoring)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "#   plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"b\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\",\n",
        "             label=\"Training score from CV\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Test score from CV\")\n",
        "\n",
        "    plt.legend(loc=\"best\",fontsize = 12)\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g25FYfIpkcR-"
      },
      "source": [
        "#Model to predict Stellar Mass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdq9T4lSnhCq"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl4Wrksz4xpZ"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model,scalespecdf,DAT, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sen9UFzO41MK"
      },
      "outputs": [],
      "source": [
        "ypred = cross_val_predict(model,scalespecdf, DAT, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9geu5frT4ydi",
        "outputId": "6d445001-ad4f-4e48-9d71-8e11b8df9da5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.where(np.abs(Mass-ypred)>0.15*(1+Mass))[0])/len(Mass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KCuFpcgVpaAe"
      },
      "outputs": [],
      "source": [
        "np.random.seed(20)\n",
        "sel = np.random.choice(range(len(ypred)), 500, replace = False) #sample without replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QalLTAuZqhwP"
      },
      "outputs": [],
      "source": [
        "seld = scalespecdf.loc[sel,:]\n",
        "selt = Mass[sel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nyFkgqwKqkU_"
      },
      "outputs": [],
      "source": [
        "littlescores = cross_validate(model,seld,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wixsfQcMqmTt",
        "outputId": "7dfa06e8-0312-40d2-ff23-189892161474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9616913866621442, 0.9942780577255419)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hLyE5rpWpauE",
        "outputId": "caea5e72-6e2c-4e7c-8267-0cddad2b57c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "Best params, best score: 0.9499 {'max_features': 400, 'min_impurity_decrease': 0.0, 'min_samples_split': 10, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "parameters = {'min_impurity_decrease':[0.1, 0.5, 0.0], \\\n",
        "              'max_features':[None,600,400], 'n_estimators':[50, 100, 200], 'min_samples_split': [10,20,100]}\n",
        "nmodels = np.product([len(el) for el in parameters.values()])\n",
        "model = GridSearchCV(RandomForestRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
        "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
        "model.fit(seld,selt)\n",
        "\n",
        "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
        "      model.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "foJ6nhY6pauH",
        "outputId": "04d966e6-510e-444f-b574-63eba3897ae7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4f64d815-f235-4aff-a763-0748a867d305\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>{'max_features': 400, 'min_impurity_decrease':...</td>\n",
              "      <td>0.949903</td>\n",
              "      <td>0.012068</td>\n",
              "      <td>0.985013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>{'max_features': 400, 'min_impurity_decrease':...</td>\n",
              "      <td>0.949842</td>\n",
              "      <td>0.012594</td>\n",
              "      <td>0.984309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>{'max_features': 600, 'min_impurity_decrease':...</td>\n",
              "      <td>0.949525</td>\n",
              "      <td>0.011608</td>\n",
              "      <td>0.984879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>0.949289</td>\n",
              "      <td>0.012234</td>\n",
              "      <td>0.984793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>{'max_features': 600, 'min_impurity_decrease':...</td>\n",
              "      <td>0.949276</td>\n",
              "      <td>0.011634</td>\n",
              "      <td>0.984614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>{'max_features': 600, 'min_impurity_decrease':...</td>\n",
              "      <td>-0.020944</td>\n",
              "      <td>0.015770</td>\n",
              "      <td>-0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>-0.020992</td>\n",
              "      <td>0.014584</td>\n",
              "      <td>-0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>{'max_features': 600, 'min_impurity_decrease':...</td>\n",
              "      <td>-0.021005</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>-0.000025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>-0.021197</td>\n",
              "      <td>0.013323</td>\n",
              "      <td>-0.000069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>{'max_features': 400, 'min_impurity_decrease':...</td>\n",
              "      <td>-0.021866</td>\n",
              "      <td>0.016328</td>\n",
              "      <td>-0.000093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f64d815-f235-4aff-a763-0748a867d305')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f64d815-f235-4aff-a763-0748a867d305 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f64d815-f235-4aff-a763-0748a867d305');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62d1625a-8b21-43e1-b898-44cb32c9d6d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62d1625a-8b21-43e1-b898-44cb32c9d6d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62d1625a-8b21-43e1-b898-44cb32c9d6d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               params  mean_test_score  \\\n",
              "74  {'max_features': 400, 'min_impurity_decrease':...         0.949903   \n",
              "72  {'max_features': 400, 'min_impurity_decrease':...         0.949842   \n",
              "47  {'max_features': 600, 'min_impurity_decrease':...         0.949525   \n",
              "19  {'max_features': None, 'min_impurity_decrease'...         0.949289   \n",
              "45  {'max_features': 600, 'min_impurity_decrease':...         0.949276   \n",
              "..                                                ...              ...   \n",
              "39  {'max_features': 600, 'min_impurity_decrease':...        -0.020944   \n",
              "10  {'max_features': None, 'min_impurity_decrease'...        -0.020992   \n",
              "36  {'max_features': 600, 'min_impurity_decrease':...        -0.021005   \n",
              "15  {'max_features': None, 'min_impurity_decrease'...        -0.021197   \n",
              "63  {'max_features': 400, 'min_impurity_decrease':...        -0.021866   \n",
              "\n",
              "    std_test_score  mean_train_score  \n",
              "74        0.012068          0.985013  \n",
              "72        0.012594          0.984309  \n",
              "47        0.011608          0.984879  \n",
              "19        0.012234          0.984793  \n",
              "45        0.011634          0.984614  \n",
              "..             ...               ...  \n",
              "39        0.015770         -0.000039  \n",
              "10        0.014584         -0.000039  \n",
              "36        0.014129         -0.000025  \n",
              "15        0.013323         -0.000069  \n",
              "63        0.016328         -0.000093  \n",
              "\n",
              "[81 rows x 4 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = pd.DataFrame(model.cv_results_)\n",
        "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
        "                                                    ascending = False)\n",
        "scoresCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI_u8TuV37st"
      },
      "source": [
        "These values are lower than my initial test value, just slightly. This tells me that they wouldn't be useful for optimization. Because the original test values are so high, I'm not too worried about increasing the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_kntPQ9kfIl"
      },
      "source": [
        "#Model to predict Dust Attenuation Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EJQfXy025IFr"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1K_CCG8H5IFs"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model,scalespecdf,DAT, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ahAU_x8F6Z5R",
        "outputId": "b8017289-a883-4440-dcb3-3e35dbde064c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([31.81377125, 32.34259677, 31.68871355, 31.65545368, 32.87206769]),\n",
              " 'score_time': array([0.0163846 , 0.01574135, 0.01564503, 0.01535034, 0.01606536]),\n",
              " 'test_score': array([0.89593475, 0.85525114, 0.90800889, 0.9032591 , 0.91922014]),\n",
              " 'train_score': array([0.98528253, 0.98784432, 0.98501129, 0.98557805, 0.98572902])}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FVgYF2RC5IFt"
      },
      "outputs": [],
      "source": [
        "ypred = cross_val_predict(model,scalespecdf, DAT, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ED1zJfs5IFu",
        "outputId": "98e7b360-2d2f-4e60-b098-a04647f5ebe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.951"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.where(np.abs(DAT-ypred)>0.15*(1+DAT))[0])/len(DAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mkiywCLCqyOV"
      },
      "outputs": [],
      "source": [
        "np.random.seed(20)\n",
        "sel = np.random.choice(range(len(ypred)), 750, replace = False) #sample without replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zKbjjoESqyOW"
      },
      "outputs": [],
      "source": [
        "seld = scalespecdf.loc[sel,:]\n",
        "selt = DAT[sel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wiOkTiew4KhG"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z7nOBwjiqyOX"
      },
      "outputs": [],
      "source": [
        "littlescores = cross_validate(model,seld,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yTYqA_3cqyOX",
        "outputId": "8d6a16d9-e543-42c0-cfcb-410ab09e79c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.886529596123608, 0.9837536399736349)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6qC4hTaQ6qOM",
        "outputId": "e8e7280f-b2fc-4716-e7cf-65e09ea0c9ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8963348038626832"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " np.mean(scores['test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2mUpK8PlvCI"
      },
      "source": [
        "##Optimization\n",
        "\n",
        "\n",
        "\n",
        "To see if optimization of tree parameters will increase test scores, I decided to run multiple different versions of the model and print out the test scores for each.\n",
        "\n",
        "This should help to show where any issues may fall, if these paramaters impact the model in a good/bad way, etc. It's a good benchmark for optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSlnrwV8ki7f",
        "outputId": "198dac8e-eca4-4e4b-f7d1-d8465254c521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "135 fits failed out of a total of 405.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "135 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got None instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.67407326 0.69175044 0.6945926  0.68089346 0.68740321 0.69065832\n",
            "        nan        nan        nan 0.37460474 0.37279438 0.37719386\n",
            " 0.37308845 0.3740326  0.37975599        nan        nan        nan\n",
            " 0.86802457 0.87624288 0.87250774 0.86776879 0.86631775 0.86743435\n",
            "        nan        nan        nan 0.67976115 0.68416025 0.68663246\n",
            " 0.67945912 0.68268221 0.68134457        nan        nan        nan\n",
            " 0.37221865 0.36661978 0.36906194 0.36987246 0.36643705 0.37131488\n",
            "        nan        nan        nan 0.86952637 0.87091291 0.87302178\n",
            " 0.86294067 0.86377165 0.86245842        nan        nan        nan\n",
            " 0.69513164 0.69478796 0.696027   0.68285733 0.69469375 0.69596555\n",
            "        nan        nan        nan 0.38508575 0.38052516 0.37783816\n",
            " 0.37715166 0.37623187 0.37836102        nan        nan        nan\n",
            " 0.87093591 0.87690608 0.87958488 0.86605017 0.86416052 0.8699204\n",
            "        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.74525436 0.75869991 0.75796824 0.74955528 0.75407561 0.76057798\n",
            "        nan        nan        nan 0.40392251 0.40498552 0.40652053\n",
            " 0.40404941 0.40494557 0.40935791        nan        nan        nan\n",
            " 0.97577615 0.97741405 0.97770103 0.95993839 0.96167216 0.96318877\n",
            "        nan        nan        nan 0.75084494 0.75483274 0.75653391\n",
            " 0.75175076 0.75148847 0.75334908        nan        nan        nan\n",
            " 0.39824749 0.39792496 0.40024817 0.40044914 0.40059769 0.40072647\n",
            "        nan        nan        nan 0.97426739 0.97663561 0.97714628\n",
            " 0.96083231 0.96156562 0.96269235        nan        nan        nan\n",
            " 0.75985436 0.76203446 0.76048485 0.75175108 0.75971161 0.76199206\n",
            "        nan        nan        nan 0.40892918 0.40689283 0.40820454\n",
            " 0.40413106 0.40625009 0.4071863         nan        nan        nan\n",
            " 0.97420775 0.97671484 0.97830926 0.9613584  0.9637976  0.96334218\n",
            "        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params, best score: 0.8796 {'max_features': None, 'min_impurity_decrease': 0.0, 'min_samples_split': 5, 'n_estimators': 75}\n"
          ]
        }
      ],
      "source": [
        "parameters = {'min_impurity_decrease':[0.1, 0.5, 0.0], \\\n",
        "              'max_features':[750,600,None], 'n_estimators':[25,50,75], 'min_samples_split': [5,10,None]}\n",
        "nmodels = np.product([len(el) for el in parameters.values()])\n",
        "model = GridSearchCV(RandomForestRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
        "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
        "model.fit(seld,selt)\n",
        "\n",
        "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
        "      model.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOlqlobAkmdx",
        "outputId": "597c1192-f9ac-4d2c-96b8-185f8b2065ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-077478ab-7e03-438f-8914-2c73aab8b04d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>0.879585</td>\n",
              "      <td>0.027854</td>\n",
              "      <td>0.978309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>0.876906</td>\n",
              "      <td>0.031756</td>\n",
              "      <td>0.976715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>{'max_features': 750, 'min_impurity_decrease':...</td>\n",
              "      <td>0.876243</td>\n",
              "      <td>0.031497</td>\n",
              "      <td>0.977414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>{'max_features': 600, 'min_impurity_decrease':...</td>\n",
              "      <td>0.873022</td>\n",
              "      <td>0.032182</td>\n",
              "      <td>0.977146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>{'max_features': 750, 'min_impurity_decrease':...</td>\n",
              "      <td>0.872508</td>\n",
              "      <td>0.029745</td>\n",
              "      <td>0.977701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>{'max_features': None, 'min_impurity_decrease'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-077478ab-7e03-438f-8914-2c73aab8b04d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-077478ab-7e03-438f-8914-2c73aab8b04d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-077478ab-7e03-438f-8914-2c73aab8b04d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee5b4ca1-3ff9-4769-8a51-d37c82b2c531\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee5b4ca1-3ff9-4769-8a51-d37c82b2c531')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee5b4ca1-3ff9-4769-8a51-d37c82b2c531 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               params  mean_test_score  \\\n",
              "74  {'max_features': None, 'min_impurity_decrease'...         0.879585   \n",
              "73  {'max_features': None, 'min_impurity_decrease'...         0.876906   \n",
              "19  {'max_features': 750, 'min_impurity_decrease':...         0.876243   \n",
              "47  {'max_features': 600, 'min_impurity_decrease':...         0.873022   \n",
              "20  {'max_features': 750, 'min_impurity_decrease':...         0.872508   \n",
              "..                                                ...              ...   \n",
              "70  {'max_features': None, 'min_impurity_decrease'...              NaN   \n",
              "71  {'max_features': None, 'min_impurity_decrease'...              NaN   \n",
              "78  {'max_features': None, 'min_impurity_decrease'...              NaN   \n",
              "79  {'max_features': None, 'min_impurity_decrease'...              NaN   \n",
              "80  {'max_features': None, 'min_impurity_decrease'...              NaN   \n",
              "\n",
              "    std_test_score  mean_train_score  \n",
              "74        0.027854          0.978309  \n",
              "73        0.031756          0.976715  \n",
              "19        0.031497          0.977414  \n",
              "47        0.032182          0.977146  \n",
              "20        0.029745          0.977701  \n",
              "..             ...               ...  \n",
              "70             NaN               NaN  \n",
              "71             NaN               NaN  \n",
              "78             NaN               NaN  \n",
              "79             NaN               NaN  \n",
              "80             NaN               NaN  \n",
              "\n",
              "[81 rows x 4 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = pd.DataFrame(model.cv_results_)\n",
        "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
        "                                                    ascending = False)\n",
        "scoresCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qW70oROTljU"
      },
      "source": [
        "With these parameters, we are able to get a small increase in our scores. I ran this a few times, tweaking based on the answers I got.\n",
        "\n",
        "With the estimators set higher and the minimum sample size at 5, the scores increase by about 1 point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDEuBByftwqZ"
      },
      "source": [
        "##Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t2-qPwXrt7hr",
        "outputId": "4796931d-0e6a-47e2-a721-6cd68c0523aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=500)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestRegressor(n_estimators=500)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RandomForestRegressor(n_estimators=500)\n",
        "model.fit(seld,selt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aHJeNdBCt7ht"
      },
      "outputs": [],
      "source": [
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JpV-Xx6yt7hu"
      },
      "outputs": [],
      "source": [
        "sels = pd.DataFrame(scalespec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U5QY9D_Nt7hv",
        "outputId": "ad5cf394-d98b-4432-c4e3-74b88e93bac6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5756a2d9-3c60-4e8f-8c1a-4926011d7991\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>840</th>\n",
              "      <th>841</th>\n",
              "      <th>842</th>\n",
              "      <th>843</th>\n",
              "      <th>844</th>\n",
              "      <th>845</th>\n",
              "      <th>846</th>\n",
              "      <th>847</th>\n",
              "      <th>848</th>\n",
              "      <th>849</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.475163</td>\n",
              "      <td>-0.473604</td>\n",
              "      <td>-0.474694</td>\n",
              "      <td>-0.474607</td>\n",
              "      <td>-0.478174</td>\n",
              "      <td>-0.484576</td>\n",
              "      <td>-0.489828</td>\n",
              "      <td>-0.483696</td>\n",
              "      <td>-0.482570</td>\n",
              "      <td>-0.473944</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.216716</td>\n",
              "      <td>-0.216058</td>\n",
              "      <td>-0.215663</td>\n",
              "      <td>-0.215148</td>\n",
              "      <td>-0.214719</td>\n",
              "      <td>-0.214418</td>\n",
              "      <td>-0.213754</td>\n",
              "      <td>-0.212460</td>\n",
              "      <td>-0.211325</td>\n",
              "      <td>-0.210914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.466753</td>\n",
              "      <td>-0.466174</td>\n",
              "      <td>-0.466116</td>\n",
              "      <td>-0.465827</td>\n",
              "      <td>-0.466203</td>\n",
              "      <td>-0.467439</td>\n",
              "      <td>-0.469383</td>\n",
              "      <td>-0.466919</td>\n",
              "      <td>-0.466717</td>\n",
              "      <td>-0.464607</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.207283</td>\n",
              "      <td>-0.206764</td>\n",
              "      <td>-0.206426</td>\n",
              "      <td>-0.206016</td>\n",
              "      <td>-0.205667</td>\n",
              "      <td>-0.205403</td>\n",
              "      <td>-0.204865</td>\n",
              "      <td>-0.203846</td>\n",
              "      <td>-0.202932</td>\n",
              "      <td>-0.202563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.509697</td>\n",
              "      <td>-0.509465</td>\n",
              "      <td>-0.508946</td>\n",
              "      <td>-0.508517</td>\n",
              "      <td>-0.507704</td>\n",
              "      <td>-0.507107</td>\n",
              "      <td>-0.507624</td>\n",
              "      <td>-0.506658</td>\n",
              "      <td>-0.506759</td>\n",
              "      <td>-0.506964</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.220173</td>\n",
              "      <td>-0.219515</td>\n",
              "      <td>-0.219131</td>\n",
              "      <td>-0.218596</td>\n",
              "      <td>-0.218146</td>\n",
              "      <td>-0.217825</td>\n",
              "      <td>-0.217147</td>\n",
              "      <td>-0.215866</td>\n",
              "      <td>-0.214743</td>\n",
              "      <td>-0.214292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.199200</td>\n",
              "      <td>-0.200158</td>\n",
              "      <td>-0.200824</td>\n",
              "      <td>-0.201716</td>\n",
              "      <td>-0.202028</td>\n",
              "      <td>-0.201030</td>\n",
              "      <td>-0.199198</td>\n",
              "      <td>-0.202611</td>\n",
              "      <td>-0.203482</td>\n",
              "      <td>-0.205833</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.204102</td>\n",
              "      <td>-0.203689</td>\n",
              "      <td>-0.203414</td>\n",
              "      <td>-0.203096</td>\n",
              "      <td>-0.202840</td>\n",
              "      <td>-0.202666</td>\n",
              "      <td>-0.202241</td>\n",
              "      <td>-0.201360</td>\n",
              "      <td>-0.200574</td>\n",
              "      <td>-0.200342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.190895</td>\n",
              "      <td>0.187301</td>\n",
              "      <td>0.186190</td>\n",
              "      <td>0.183713</td>\n",
              "      <td>0.185021</td>\n",
              "      <td>0.192503</td>\n",
              "      <td>0.203966</td>\n",
              "      <td>0.187959</td>\n",
              "      <td>0.185364</td>\n",
              "      <td>0.173216</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.195729</td>\n",
              "      <td>-0.195372</td>\n",
              "      <td>-0.195142</td>\n",
              "      <td>-0.194908</td>\n",
              "      <td>-0.194745</td>\n",
              "      <td>-0.194675</td>\n",
              "      <td>-0.194332</td>\n",
              "      <td>-0.193512</td>\n",
              "      <td>-0.192786</td>\n",
              "      <td>-0.192713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-0.102020</td>\n",
              "      <td>-0.102618</td>\n",
              "      <td>-0.101422</td>\n",
              "      <td>-0.101185</td>\n",
              "      <td>-0.098264</td>\n",
              "      <td>-0.091375</td>\n",
              "      <td>-0.082330</td>\n",
              "      <td>-0.090878</td>\n",
              "      <td>-0.091024</td>\n",
              "      <td>-0.097679</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.123099</td>\n",
              "      <td>-0.123181</td>\n",
              "      <td>-0.123199</td>\n",
              "      <td>-0.123214</td>\n",
              "      <td>-0.123218</td>\n",
              "      <td>-0.123188</td>\n",
              "      <td>-0.123234</td>\n",
              "      <td>-0.123344</td>\n",
              "      <td>-0.123419</td>\n",
              "      <td>-0.123363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-0.455463</td>\n",
              "      <td>-0.455163</td>\n",
              "      <td>-0.453691</td>\n",
              "      <td>-0.452757</td>\n",
              "      <td>-0.450094</td>\n",
              "      <td>-0.446363</td>\n",
              "      <td>-0.444385</td>\n",
              "      <td>-0.445013</td>\n",
              "      <td>-0.445004</td>\n",
              "      <td>-0.447863</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175921</td>\n",
              "      <td>-0.174777</td>\n",
              "      <td>-0.174330</td>\n",
              "      <td>-0.173352</td>\n",
              "      <td>-0.172533</td>\n",
              "      <td>-0.171935</td>\n",
              "      <td>-0.170856</td>\n",
              "      <td>-0.168969</td>\n",
              "      <td>-0.167390</td>\n",
              "      <td>-0.166550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.245249</td>\n",
              "      <td>0.241062</td>\n",
              "      <td>0.240056</td>\n",
              "      <td>0.237343</td>\n",
              "      <td>0.239401</td>\n",
              "      <td>0.248944</td>\n",
              "      <td>0.263195</td>\n",
              "      <td>0.243885</td>\n",
              "      <td>0.240913</td>\n",
              "      <td>0.226047</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.193422</td>\n",
              "      <td>-0.193101</td>\n",
              "      <td>-0.192893</td>\n",
              "      <td>-0.192685</td>\n",
              "      <td>-0.192545</td>\n",
              "      <td>-0.192493</td>\n",
              "      <td>-0.192186</td>\n",
              "      <td>-0.191425</td>\n",
              "      <td>-0.190752</td>\n",
              "      <td>-0.190707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-0.401726</td>\n",
              "      <td>-0.401438</td>\n",
              "      <td>-0.401175</td>\n",
              "      <td>-0.400916</td>\n",
              "      <td>-0.400631</td>\n",
              "      <td>-0.400428</td>\n",
              "      <td>-0.400701</td>\n",
              "      <td>-0.400032</td>\n",
              "      <td>-0.399996</td>\n",
              "      <td>-0.399644</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.203466</td>\n",
              "      <td>-0.202917</td>\n",
              "      <td>-0.202584</td>\n",
              "      <td>-0.202147</td>\n",
              "      <td>-0.201780</td>\n",
              "      <td>-0.201512</td>\n",
              "      <td>-0.200954</td>\n",
              "      <td>-0.199887</td>\n",
              "      <td>-0.198941</td>\n",
              "      <td>-0.198569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-0.293953</td>\n",
              "      <td>-0.294014</td>\n",
              "      <td>-0.292593</td>\n",
              "      <td>-0.291903</td>\n",
              "      <td>-0.289061</td>\n",
              "      <td>-0.283611</td>\n",
              "      <td>-0.277298</td>\n",
              "      <td>-0.282476</td>\n",
              "      <td>-0.282373</td>\n",
              "      <td>-0.287031</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.174098</td>\n",
              "      <td>-0.173304</td>\n",
              "      <td>-0.172943</td>\n",
              "      <td>-0.172299</td>\n",
              "      <td>-0.171767</td>\n",
              "      <td>-0.171394</td>\n",
              "      <td>-0.170641</td>\n",
              "      <td>-0.169244</td>\n",
              "      <td>-0.168055</td>\n",
              "      <td>-0.167542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 850 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5756a2d9-3c60-4e8f-8c1a-4926011d7991')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5756a2d9-3c60-4e8f-8c1a-4926011d7991 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5756a2d9-3c60-4e8f-8c1a-4926011d7991');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebef10c2-cb2a-48ea-98ce-4315436190d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebef10c2-cb2a-48ea-98ce-4315436190d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebef10c2-cb2a-48ea-98ce-4315436190d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6    \\\n",
              "0   -0.475163 -0.473604 -0.474694 -0.474607 -0.478174 -0.484576 -0.489828   \n",
              "1   -0.466753 -0.466174 -0.466116 -0.465827 -0.466203 -0.467439 -0.469383   \n",
              "2   -0.509697 -0.509465 -0.508946 -0.508517 -0.507704 -0.507107 -0.507624   \n",
              "3   -0.199200 -0.200158 -0.200824 -0.201716 -0.202028 -0.201030 -0.199198   \n",
              "4    0.190895  0.187301  0.186190  0.183713  0.185021  0.192503  0.203966   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "995 -0.102020 -0.102618 -0.101422 -0.101185 -0.098264 -0.091375 -0.082330   \n",
              "996 -0.455463 -0.455163 -0.453691 -0.452757 -0.450094 -0.446363 -0.444385   \n",
              "997  0.245249  0.241062  0.240056  0.237343  0.239401  0.248944  0.263195   \n",
              "998 -0.401726 -0.401438 -0.401175 -0.400916 -0.400631 -0.400428 -0.400701   \n",
              "999 -0.293953 -0.294014 -0.292593 -0.291903 -0.289061 -0.283611 -0.277298   \n",
              "\n",
              "          7         8         9    ...       840       841       842  \\\n",
              "0   -0.483696 -0.482570 -0.473944  ... -0.216716 -0.216058 -0.215663   \n",
              "1   -0.466919 -0.466717 -0.464607  ... -0.207283 -0.206764 -0.206426   \n",
              "2   -0.506658 -0.506759 -0.506964  ... -0.220173 -0.219515 -0.219131   \n",
              "3   -0.202611 -0.203482 -0.205833  ... -0.204102 -0.203689 -0.203414   \n",
              "4    0.187959  0.185364  0.173216  ... -0.195729 -0.195372 -0.195142   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "995 -0.090878 -0.091024 -0.097679  ... -0.123099 -0.123181 -0.123199   \n",
              "996 -0.445013 -0.445004 -0.447863  ... -0.175921 -0.174777 -0.174330   \n",
              "997  0.243885  0.240913  0.226047  ... -0.193422 -0.193101 -0.192893   \n",
              "998 -0.400032 -0.399996 -0.399644  ... -0.203466 -0.202917 -0.202584   \n",
              "999 -0.282476 -0.282373 -0.287031  ... -0.174098 -0.173304 -0.172943   \n",
              "\n",
              "          843       844       845       846       847       848       849  \n",
              "0   -0.215148 -0.214719 -0.214418 -0.213754 -0.212460 -0.211325 -0.210914  \n",
              "1   -0.206016 -0.205667 -0.205403 -0.204865 -0.203846 -0.202932 -0.202563  \n",
              "2   -0.218596 -0.218146 -0.217825 -0.217147 -0.215866 -0.214743 -0.214292  \n",
              "3   -0.203096 -0.202840 -0.202666 -0.202241 -0.201360 -0.200574 -0.200342  \n",
              "4   -0.194908 -0.194745 -0.194675 -0.194332 -0.193512 -0.192786 -0.192713  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "995 -0.123214 -0.123218 -0.123188 -0.123234 -0.123344 -0.123419 -0.123363  \n",
              "996 -0.173352 -0.172533 -0.171935 -0.170856 -0.168969 -0.167390 -0.166550  \n",
              "997 -0.192685 -0.192545 -0.192493 -0.192186 -0.191425 -0.190752 -0.190707  \n",
              "998 -0.202147 -0.201780 -0.201512 -0.200954 -0.199887 -0.198941 -0.198569  \n",
              "999 -0.172299 -0.171767 -0.171394 -0.170641 -0.169244 -0.168055 -0.167542  \n",
              "\n",
              "[1000 rows x 850 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4Itvyyqht7hw",
        "outputId": "4db48874-b2fa-478d-fbef-1a7bdd6f2419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "1. feature: 760, 760 (0.626864)\n",
            "2. feature: 6, 6 (0.022781)\n",
            "3. feature: 759, 759 (0.012855)\n",
            "4. feature: 1, 1 (0.012143)\n",
            "5. feature: 5, 5 (0.010008)\n",
            "6. feature: 0, 0 (0.010003)\n",
            "7. feature: 4, 4 (0.006436)\n",
            "8. feature: 2, 2 (0.006171)\n",
            "9. feature: 3, 3 (0.006000)\n",
            "10. feature: 758, 758 (0.005056)\n",
            "11. feature: 7, 7 (0.004681)\n",
            "12. feature: 307, 307 (0.004458)\n",
            "13. feature: 761, 761 (0.004400)\n",
            "14. feature: 8, 8 (0.004153)\n",
            "15. feature: 400, 400 (0.004008)\n",
            "16. feature: 348, 348 (0.003759)\n",
            "17. feature: 445, 445 (0.003635)\n",
            "18. feature: 490, 490 (0.003537)\n",
            "19. feature: 17, 17 (0.002998)\n",
            "20. feature: 12, 12 (0.002788)\n",
            "21. feature: 554, 554 (0.002742)\n",
            "22. feature: 402, 402 (0.002578)\n",
            "23. feature: 10, 10 (0.002494)\n",
            "24. feature: 13, 13 (0.002488)\n",
            "25. feature: 467, 467 (0.002487)\n",
            "26. feature: 409, 409 (0.002464)\n",
            "27. feature: 385, 385 (0.002145)\n",
            "28. feature: 344, 344 (0.002126)\n",
            "29. feature: 381, 381 (0.002023)\n",
            "30. feature: 26, 26 (0.001839)\n",
            "31. feature: 497, 497 (0.001772)\n",
            "32. feature: 11, 11 (0.001700)\n",
            "33. feature: 25, 25 (0.001652)\n",
            "34. feature: 9, 9 (0.001640)\n",
            "35. feature: 620, 620 (0.001551)\n",
            "36. feature: 286, 286 (0.001523)\n",
            "37. feature: 16, 16 (0.001521)\n",
            "38. feature: 36, 36 (0.001512)\n",
            "39. feature: 14, 14 (0.001493)\n",
            "40. feature: 21, 21 (0.001477)\n",
            "41. feature: 305, 305 (0.001417)\n",
            "42. feature: 303, 303 (0.001398)\n",
            "43. feature: 427, 427 (0.001380)\n",
            "44. feature: 834, 834 (0.001373)\n",
            "45. feature: 37, 37 (0.001373)\n",
            "46. feature: 19, 19 (0.001343)\n",
            "47. feature: 359, 359 (0.001341)\n",
            "48. feature: 483, 483 (0.001332)\n",
            "49. feature: 23, 23 (0.001315)\n",
            "50. feature: 33, 33 (0.001289)\n",
            "51. feature: 403, 403 (0.001288)\n",
            "52. feature: 757, 757 (0.001283)\n",
            "53. feature: 20, 20 (0.001281)\n",
            "54. feature: 283, 283 (0.001265)\n",
            "55. feature: 28, 28 (0.001250)\n",
            "56. feature: 684, 684 (0.001248)\n",
            "57. feature: 15, 15 (0.001200)\n",
            "58. feature: 43, 43 (0.001151)\n",
            "59. feature: 30, 30 (0.001127)\n",
            "60. feature: 18, 18 (0.001118)\n",
            "61. feature: 24, 24 (0.001092)\n",
            "62. feature: 35, 35 (0.001074)\n",
            "63. feature: 482, 482 (0.001065)\n",
            "64. feature: 22, 22 (0.001047)\n",
            "65. feature: 456, 456 (0.001016)\n",
            "66. feature: 298, 298 (0.001011)\n",
            "67. feature: 282, 282 (0.001007)\n",
            "68. feature: 301, 301 (0.001003)\n",
            "69. feature: 350, 350 (0.000970)\n",
            "70. feature: 74, 74 (0.000937)\n",
            "71. feature: 31, 31 (0.000936)\n",
            "72. feature: 53, 53 (0.000921)\n",
            "73. feature: 50, 50 (0.000916)\n",
            "74. feature: 324, 324 (0.000896)\n",
            "75. feature: 474, 474 (0.000894)\n",
            "76. feature: 479, 479 (0.000875)\n",
            "77. feature: 55, 55 (0.000875)\n",
            "78. feature: 41, 41 (0.000865)\n",
            "79. feature: 460, 460 (0.000846)\n",
            "80. feature: 313, 313 (0.000787)\n",
            "81. feature: 306, 306 (0.000761)\n",
            "82. feature: 291, 291 (0.000758)\n",
            "83. feature: 424, 424 (0.000758)\n",
            "84. feature: 302, 302 (0.000756)\n",
            "85. feature: 452, 452 (0.000738)\n",
            "86. feature: 429, 429 (0.000727)\n",
            "87. feature: 395, 395 (0.000714)\n",
            "88. feature: 48, 48 (0.000710)\n",
            "89. feature: 459, 459 (0.000705)\n",
            "90. feature: 266, 266 (0.000691)\n",
            "91. feature: 762, 762 (0.000689)\n",
            "92. feature: 294, 294 (0.000685)\n",
            "93. feature: 27, 27 (0.000684)\n",
            "94. feature: 478, 478 (0.000678)\n",
            "95. feature: 470, 470 (0.000675)\n",
            "96. feature: 462, 462 (0.000671)\n",
            "97. feature: 284, 284 (0.000667)\n",
            "98. feature: 46, 46 (0.000663)\n",
            "99. feature: 630, 630 (0.000649)\n",
            "100. feature: 682, 682 (0.000647)\n",
            "101. feature: 54, 54 (0.000640)\n",
            "102. feature: 297, 297 (0.000630)\n",
            "103. feature: 440, 440 (0.000630)\n",
            "104. feature: 45, 45 (0.000628)\n",
            "105. feature: 435, 435 (0.000626)\n",
            "106. feature: 34, 34 (0.000626)\n",
            "107. feature: 352, 352 (0.000615)\n",
            "108. feature: 343, 343 (0.000610)\n",
            "109. feature: 418, 418 (0.000603)\n",
            "110. feature: 289, 289 (0.000597)\n",
            "111. feature: 319, 319 (0.000595)\n",
            "112. feature: 396, 396 (0.000590)\n",
            "113. feature: 397, 397 (0.000586)\n",
            "114. feature: 32, 32 (0.000573)\n",
            "115. feature: 430, 430 (0.000569)\n",
            "116. feature: 326, 326 (0.000568)\n",
            "117. feature: 362, 362 (0.000567)\n",
            "118. feature: 280, 280 (0.000564)\n",
            "119. feature: 406, 406 (0.000563)\n",
            "120. feature: 719, 719 (0.000562)\n",
            "121. feature: 323, 323 (0.000560)\n",
            "122. feature: 401, 401 (0.000559)\n",
            "123. feature: 449, 449 (0.000552)\n",
            "124. feature: 300, 300 (0.000545)\n",
            "125. feature: 408, 408 (0.000535)\n",
            "126. feature: 371, 371 (0.000534)\n",
            "127. feature: 61, 61 (0.000526)\n",
            "128. feature: 690, 690 (0.000524)\n",
            "129. feature: 448, 448 (0.000506)\n",
            "130. feature: 304, 304 (0.000491)\n",
            "131. feature: 49, 49 (0.000485)\n",
            "132. feature: 340, 340 (0.000481)\n",
            "133. feature: 463, 463 (0.000473)\n",
            "134. feature: 686, 686 (0.000472)\n",
            "135. feature: 51, 51 (0.000472)\n",
            "136. feature: 428, 428 (0.000464)\n",
            "137. feature: 425, 425 (0.000463)\n",
            "138. feature: 575, 575 (0.000460)\n",
            "139. feature: 374, 374 (0.000457)\n",
            "140. feature: 293, 293 (0.000455)\n",
            "141. feature: 47, 47 (0.000453)\n",
            "142. feature: 373, 373 (0.000451)\n",
            "143. feature: 325, 325 (0.000449)\n",
            "144. feature: 393, 393 (0.000448)\n",
            "145. feature: 299, 299 (0.000446)\n",
            "146. feature: 315, 315 (0.000446)\n",
            "147. feature: 394, 394 (0.000443)\n",
            "148. feature: 329, 329 (0.000442)\n",
            "149. feature: 287, 287 (0.000440)\n",
            "150. feature: 364, 364 (0.000438)\n",
            "151. feature: 382, 382 (0.000437)\n",
            "152. feature: 688, 688 (0.000435)\n",
            "153. feature: 57, 57 (0.000429)\n",
            "154. feature: 336, 336 (0.000426)\n",
            "155. feature: 316, 316 (0.000423)\n",
            "156. feature: 471, 471 (0.000423)\n",
            "157. feature: 29, 29 (0.000422)\n",
            "158. feature: 603, 603 (0.000421)\n",
            "159. feature: 458, 458 (0.000412)\n",
            "160. feature: 446, 446 (0.000409)\n",
            "161. feature: 42, 42 (0.000409)\n",
            "162. feature: 330, 330 (0.000409)\n",
            "163. feature: 353, 353 (0.000403)\n",
            "164. feature: 288, 288 (0.000398)\n",
            "165. feature: 387, 387 (0.000392)\n",
            "166. feature: 38, 38 (0.000392)\n",
            "167. feature: 312, 312 (0.000392)\n",
            "168. feature: 805, 805 (0.000389)\n",
            "169. feature: 426, 426 (0.000388)\n",
            "170. feature: 59, 59 (0.000387)\n",
            "171. feature: 82, 82 (0.000384)\n",
            "172. feature: 485, 485 (0.000384)\n",
            "173. feature: 726, 726 (0.000381)\n",
            "174. feature: 507, 507 (0.000379)\n",
            "175. feature: 285, 285 (0.000377)\n",
            "176. feature: 437, 437 (0.000375)\n",
            "177. feature: 351, 351 (0.000373)\n",
            "178. feature: 366, 366 (0.000372)\n",
            "179. feature: 310, 310 (0.000371)\n",
            "180. feature: 281, 281 (0.000370)\n",
            "181. feature: 475, 475 (0.000368)\n",
            "182. feature: 469, 469 (0.000368)\n",
            "183. feature: 484, 484 (0.000367)\n",
            "184. feature: 365, 365 (0.000366)\n",
            "185. feature: 60, 60 (0.000363)\n",
            "186. feature: 320, 320 (0.000361)\n",
            "187. feature: 341, 341 (0.000361)\n",
            "188. feature: 523, 523 (0.000361)\n",
            "189. feature: 309, 309 (0.000360)\n",
            "190. feature: 333, 333 (0.000360)\n",
            "191. feature: 442, 442 (0.000357)\n",
            "192. feature: 338, 338 (0.000355)\n",
            "193. feature: 263, 263 (0.000355)\n",
            "194. feature: 56, 56 (0.000354)\n",
            "195. feature: 419, 419 (0.000351)\n",
            "196. feature: 421, 421 (0.000349)\n",
            "197. feature: 295, 295 (0.000346)\n",
            "198. feature: 461, 461 (0.000345)\n",
            "199. feature: 290, 290 (0.000344)\n",
            "200. feature: 67, 67 (0.000342)\n",
            "201. feature: 363, 363 (0.000342)\n",
            "202. feature: 720, 720 (0.000340)\n",
            "203. feature: 383, 383 (0.000339)\n",
            "204. feature: 327, 327 (0.000335)\n",
            "205. feature: 103, 103 (0.000335)\n",
            "206. feature: 81, 81 (0.000332)\n",
            "207. feature: 380, 380 (0.000332)\n",
            "208. feature: 404, 404 (0.000332)\n",
            "209. feature: 498, 498 (0.000330)\n",
            "210. feature: 249, 249 (0.000330)\n",
            "211. feature: 39, 39 (0.000326)\n",
            "212. feature: 335, 335 (0.000326)\n",
            "213. feature: 90, 90 (0.000324)\n",
            "214. feature: 52, 52 (0.000322)\n",
            "215. feature: 689, 689 (0.000320)\n",
            "216. feature: 592, 592 (0.000316)\n",
            "217. feature: 368, 368 (0.000313)\n",
            "218. feature: 224, 224 (0.000313)\n",
            "219. feature: 506, 506 (0.000312)\n",
            "220. feature: 556, 556 (0.000311)\n",
            "221. feature: 228, 228 (0.000311)\n",
            "222. feature: 451, 451 (0.000309)\n",
            "223. feature: 626, 626 (0.000309)\n",
            "224. feature: 423, 423 (0.000309)\n",
            "225. feature: 723, 723 (0.000309)\n",
            "226. feature: 433, 433 (0.000307)\n",
            "227. feature: 443, 443 (0.000306)\n",
            "228. feature: 477, 477 (0.000306)\n",
            "229. feature: 314, 314 (0.000303)\n",
            "230. feature: 585, 585 (0.000302)\n",
            "231. feature: 354, 354 (0.000302)\n",
            "232. feature: 457, 457 (0.000301)\n",
            "233. feature: 321, 321 (0.000301)\n",
            "234. feature: 216, 216 (0.000298)\n",
            "235. feature: 420, 420 (0.000298)\n",
            "236. feature: 476, 476 (0.000297)\n",
            "237. feature: 355, 355 (0.000297)\n",
            "238. feature: 80, 80 (0.000293)\n",
            "239. feature: 318, 318 (0.000293)\n",
            "240. feature: 710, 710 (0.000293)\n",
            "241. feature: 370, 370 (0.000292)\n",
            "242. feature: 66, 66 (0.000291)\n",
            "243. feature: 372, 372 (0.000291)\n",
            "244. feature: 763, 763 (0.000290)\n",
            "245. feature: 737, 737 (0.000290)\n",
            "246. feature: 583, 583 (0.000289)\n",
            "247. feature: 698, 698 (0.000289)\n",
            "248. feature: 311, 311 (0.000288)\n",
            "249. feature: 334, 334 (0.000286)\n",
            "250. feature: 436, 436 (0.000284)\n",
            "251. feature: 496, 496 (0.000283)\n",
            "252. feature: 356, 356 (0.000281)\n",
            "253. feature: 413, 413 (0.000281)\n",
            "254. feature: 439, 439 (0.000281)\n",
            "255. feature: 466, 466 (0.000281)\n",
            "256. feature: 464, 464 (0.000280)\n",
            "257. feature: 96, 96 (0.000278)\n",
            "258. feature: 728, 728 (0.000278)\n",
            "259. feature: 520, 520 (0.000278)\n",
            "260. feature: 647, 647 (0.000277)\n",
            "261. feature: 590, 590 (0.000276)\n",
            "262. feature: 367, 367 (0.000274)\n",
            "263. feature: 191, 191 (0.000272)\n",
            "264. feature: 725, 725 (0.000272)\n",
            "265. feature: 417, 417 (0.000272)\n",
            "266. feature: 576, 576 (0.000271)\n",
            "267. feature: 438, 438 (0.000271)\n",
            "268. feature: 240, 240 (0.000270)\n",
            "269. feature: 580, 580 (0.000269)\n",
            "270. feature: 608, 608 (0.000268)\n",
            "271. feature: 258, 258 (0.000267)\n",
            "272. feature: 95, 95 (0.000267)\n",
            "273. feature: 292, 292 (0.000267)\n",
            "274. feature: 58, 58 (0.000266)\n",
            "275. feature: 89, 89 (0.000263)\n",
            "276. feature: 122, 122 (0.000263)\n",
            "277. feature: 455, 455 (0.000261)\n",
            "278. feature: 389, 389 (0.000261)\n",
            "279. feature: 388, 388 (0.000261)\n",
            "280. feature: 495, 495 (0.000260)\n",
            "281. feature: 349, 349 (0.000260)\n",
            "282. feature: 391, 391 (0.000259)\n",
            "283. feature: 541, 541 (0.000259)\n",
            "284. feature: 386, 386 (0.000259)\n",
            "285. feature: 724, 724 (0.000258)\n",
            "286. feature: 444, 444 (0.000258)\n",
            "287. feature: 504, 504 (0.000257)\n",
            "288. feature: 412, 412 (0.000257)\n",
            "289. feature: 632, 632 (0.000256)\n",
            "290. feature: 555, 555 (0.000254)\n",
            "291. feature: 528, 528 (0.000253)\n",
            "292. feature: 768, 768 (0.000253)\n",
            "293. feature: 540, 540 (0.000252)\n",
            "294. feature: 828, 828 (0.000252)\n",
            "295. feature: 44, 44 (0.000252)\n",
            "296. feature: 337, 337 (0.000252)\n",
            "297. feature: 713, 713 (0.000252)\n",
            "298. feature: 526, 526 (0.000251)\n",
            "299. feature: 450, 450 (0.000251)\n",
            "300. feature: 531, 531 (0.000248)\n",
            "301. feature: 481, 481 (0.000248)\n",
            "302. feature: 447, 447 (0.000248)\n",
            "303. feature: 612, 612 (0.000247)\n",
            "304. feature: 553, 553 (0.000246)\n",
            "305. feature: 787, 787 (0.000244)\n",
            "306. feature: 93, 93 (0.000242)\n",
            "307. feature: 147, 147 (0.000242)\n",
            "308. feature: 522, 522 (0.000241)\n",
            "309. feature: 652, 652 (0.000240)\n",
            "310. feature: 588, 588 (0.000238)\n",
            "311. feature: 624, 624 (0.000238)\n",
            "312. feature: 718, 718 (0.000238)\n",
            "313. feature: 414, 414 (0.000237)\n",
            "314. feature: 208, 208 (0.000237)\n",
            "315. feature: 331, 331 (0.000236)\n",
            "316. feature: 722, 722 (0.000235)\n",
            "317. feature: 691, 691 (0.000234)\n",
            "318. feature: 579, 579 (0.000234)\n",
            "319. feature: 747, 747 (0.000233)\n",
            "320. feature: 328, 328 (0.000233)\n",
            "321. feature: 85, 85 (0.000232)\n",
            "322. feature: 465, 465 (0.000232)\n",
            "323. feature: 415, 415 (0.000232)\n",
            "324. feature: 605, 605 (0.000231)\n",
            "325. feature: 317, 317 (0.000231)\n",
            "326. feature: 375, 375 (0.000230)\n",
            "327. feature: 71, 71 (0.000230)\n",
            "328. feature: 551, 551 (0.000230)\n",
            "329. feature: 378, 378 (0.000229)\n",
            "330. feature: 454, 454 (0.000229)\n",
            "331. feature: 621, 621 (0.000227)\n",
            "332. feature: 377, 377 (0.000227)\n",
            "333. feature: 190, 190 (0.000227)\n",
            "334. feature: 639, 639 (0.000226)\n",
            "335. feature: 472, 472 (0.000225)\n",
            "336. feature: 493, 493 (0.000224)\n",
            "337. feature: 441, 441 (0.000224)\n",
            "338. feature: 357, 357 (0.000224)\n",
            "339. feature: 643, 643 (0.000221)\n",
            "340. feature: 487, 487 (0.000221)\n",
            "341. feature: 756, 756 (0.000220)\n",
            "342. feature: 345, 345 (0.000220)\n",
            "343. feature: 587, 587 (0.000220)\n",
            "344. feature: 77, 77 (0.000219)\n",
            "345. feature: 730, 730 (0.000219)\n",
            "346. feature: 64, 64 (0.000218)\n",
            "347. feature: 392, 392 (0.000218)\n",
            "348. feature: 573, 573 (0.000217)\n",
            "349. feature: 629, 629 (0.000216)\n",
            "350. feature: 530, 530 (0.000216)\n",
            "351. feature: 296, 296 (0.000215)\n",
            "352. feature: 668, 668 (0.000215)\n",
            "353. feature: 640, 640 (0.000214)\n",
            "354. feature: 225, 225 (0.000214)\n",
            "355. feature: 360, 360 (0.000213)\n",
            "356. feature: 563, 563 (0.000212)\n",
            "357. feature: 627, 627 (0.000212)\n",
            "358. feature: 752, 752 (0.000212)\n",
            "359. feature: 687, 687 (0.000211)\n",
            "360. feature: 777, 777 (0.000211)\n",
            "361. feature: 405, 405 (0.000210)\n",
            "362. feature: 358, 358 (0.000210)\n",
            "363. feature: 564, 564 (0.000210)\n",
            "364. feature: 489, 489 (0.000210)\n",
            "365. feature: 376, 376 (0.000210)\n",
            "366. feature: 676, 676 (0.000210)\n",
            "367. feature: 527, 527 (0.000210)\n",
            "368. feature: 502, 502 (0.000210)\n",
            "369. feature: 422, 422 (0.000209)\n",
            "370. feature: 257, 257 (0.000207)\n",
            "371. feature: 515, 515 (0.000207)\n",
            "372. feature: 776, 776 (0.000206)\n",
            "373. feature: 784, 784 (0.000206)\n",
            "374. feature: 142, 142 (0.000205)\n",
            "375. feature: 840, 840 (0.000205)\n",
            "376. feature: 332, 332 (0.000204)\n",
            "377. feature: 247, 247 (0.000204)\n",
            "378. feature: 602, 602 (0.000204)\n",
            "379. feature: 693, 693 (0.000204)\n",
            "380. feature: 848, 848 (0.000202)\n",
            "381. feature: 511, 511 (0.000202)\n",
            "382. feature: 272, 272 (0.000202)\n",
            "383. feature: 194, 194 (0.000201)\n",
            "384. feature: 755, 755 (0.000201)\n",
            "385. feature: 635, 635 (0.000201)\n",
            "386. feature: 202, 202 (0.000201)\n",
            "387. feature: 252, 252 (0.000201)\n",
            "388. feature: 491, 491 (0.000201)\n",
            "389. feature: 655, 655 (0.000200)\n",
            "390. feature: 165, 165 (0.000199)\n",
            "391. feature: 721, 721 (0.000199)\n",
            "392. feature: 617, 617 (0.000199)\n",
            "393. feature: 245, 245 (0.000199)\n",
            "394. feature: 211, 211 (0.000198)\n",
            "395. feature: 339, 339 (0.000198)\n",
            "396. feature: 277, 277 (0.000197)\n",
            "397. feature: 390, 390 (0.000197)\n",
            "398. feature: 534, 534 (0.000197)\n",
            "399. feature: 616, 616 (0.000196)\n",
            "400. feature: 524, 524 (0.000195)\n",
            "401. feature: 104, 104 (0.000195)\n",
            "402. feature: 68, 68 (0.000195)\n",
            "403. feature: 536, 536 (0.000194)\n",
            "404. feature: 702, 702 (0.000193)\n",
            "405. feature: 499, 499 (0.000193)\n",
            "406. feature: 509, 509 (0.000193)\n",
            "407. feature: 623, 623 (0.000193)\n",
            "408. feature: 778, 778 (0.000192)\n",
            "409. feature: 91, 91 (0.000191)\n",
            "410. feature: 558, 558 (0.000191)\n",
            "411. feature: 275, 275 (0.000191)\n",
            "412. feature: 513, 513 (0.000190)\n",
            "413. feature: 346, 346 (0.000190)\n",
            "414. feature: 578, 578 (0.000188)\n",
            "415. feature: 369, 369 (0.000188)\n",
            "416. feature: 572, 572 (0.000188)\n",
            "417. feature: 182, 182 (0.000187)\n",
            "418. feature: 651, 651 (0.000187)\n",
            "419. feature: 432, 432 (0.000186)\n",
            "420. feature: 62, 62 (0.000186)\n",
            "421. feature: 566, 566 (0.000185)\n",
            "422. feature: 97, 97 (0.000185)\n",
            "423. feature: 609, 609 (0.000184)\n",
            "424. feature: 274, 274 (0.000184)\n",
            "425. feature: 586, 586 (0.000184)\n",
            "426. feature: 107, 107 (0.000183)\n",
            "427. feature: 87, 87 (0.000183)\n",
            "428. feature: 604, 604 (0.000183)\n",
            "429. feature: 63, 63 (0.000182)\n",
            "430. feature: 242, 242 (0.000182)\n",
            "431. feature: 488, 488 (0.000182)\n",
            "432. feature: 570, 570 (0.000182)\n",
            "433. feature: 641, 641 (0.000180)\n",
            "434. feature: 653, 653 (0.000179)\n",
            "435. feature: 715, 715 (0.000177)\n",
            "436. feature: 569, 569 (0.000175)\n",
            "437. feature: 571, 571 (0.000175)\n",
            "438. feature: 86, 86 (0.000175)\n",
            "439. feature: 308, 308 (0.000174)\n",
            "440. feature: 611, 611 (0.000173)\n",
            "441. feature: 846, 846 (0.000173)\n",
            "442. feature: 656, 656 (0.000173)\n",
            "443. feature: 664, 664 (0.000172)\n",
            "444. feature: 843, 843 (0.000172)\n",
            "445. feature: 407, 407 (0.000171)\n",
            "446. feature: 434, 434 (0.000171)\n",
            "447. feature: 669, 669 (0.000171)\n",
            "448. feature: 597, 597 (0.000171)\n",
            "449. feature: 384, 384 (0.000170)\n",
            "450. feature: 410, 410 (0.000169)\n",
            "451. feature: 717, 717 (0.000169)\n",
            "452. feature: 510, 510 (0.000168)\n",
            "453. feature: 800, 800 (0.000168)\n",
            "454. feature: 751, 751 (0.000167)\n",
            "455. feature: 72, 72 (0.000166)\n",
            "456. feature: 241, 241 (0.000166)\n",
            "457. feature: 815, 815 (0.000165)\n",
            "458. feature: 748, 748 (0.000165)\n",
            "459. feature: 207, 207 (0.000164)\n",
            "460. feature: 794, 794 (0.000164)\n",
            "461. feature: 278, 278 (0.000163)\n",
            "462. feature: 162, 162 (0.000162)\n",
            "463. feature: 744, 744 (0.000162)\n",
            "464. feature: 814, 814 (0.000162)\n",
            "465. feature: 711, 711 (0.000159)\n",
            "466. feature: 704, 704 (0.000159)\n",
            "467. feature: 521, 521 (0.000159)\n",
            "468. feature: 468, 468 (0.000158)\n",
            "469. feature: 574, 574 (0.000158)\n",
            "470. feature: 508, 508 (0.000157)\n",
            "471. feature: 750, 750 (0.000157)\n",
            "472. feature: 453, 453 (0.000157)\n",
            "473. feature: 660, 660 (0.000157)\n",
            "474. feature: 552, 552 (0.000155)\n",
            "475. feature: 601, 601 (0.000155)\n",
            "476. feature: 662, 662 (0.000155)\n",
            "477. feature: 712, 712 (0.000153)\n",
            "478. feature: 251, 251 (0.000153)\n",
            "479. feature: 265, 265 (0.000152)\n",
            "480. feature: 598, 598 (0.000152)\n",
            "481. feature: 745, 745 (0.000152)\n",
            "482. feature: 678, 678 (0.000152)\n",
            "483. feature: 135, 135 (0.000151)\n",
            "484. feature: 809, 809 (0.000151)\n",
            "485. feature: 40, 40 (0.000151)\n",
            "486. feature: 99, 99 (0.000151)\n",
            "487. feature: 628, 628 (0.000151)\n",
            "488. feature: 754, 754 (0.000150)\n",
            "489. feature: 696, 696 (0.000150)\n",
            "490. feature: 517, 517 (0.000150)\n",
            "491. feature: 159, 159 (0.000150)\n",
            "492. feature: 550, 550 (0.000149)\n",
            "493. feature: 827, 827 (0.000147)\n",
            "494. feature: 399, 399 (0.000147)\n",
            "495. feature: 792, 792 (0.000146)\n",
            "496. feature: 512, 512 (0.000146)\n",
            "497. feature: 634, 634 (0.000146)\n",
            "498. feature: 361, 361 (0.000146)\n",
            "499. feature: 599, 599 (0.000146)\n",
            "500. feature: 584, 584 (0.000145)\n",
            "501. feature: 568, 568 (0.000145)\n",
            "502. feature: 613, 613 (0.000145)\n",
            "503. feature: 731, 731 (0.000144)\n",
            "504. feature: 729, 729 (0.000144)\n",
            "505. feature: 782, 782 (0.000144)\n",
            "506. feature: 101, 101 (0.000144)\n",
            "507. feature: 532, 532 (0.000144)\n",
            "508. feature: 622, 622 (0.000144)\n",
            "509. feature: 685, 685 (0.000144)\n",
            "510. feature: 501, 501 (0.000143)\n",
            "511. feature: 494, 494 (0.000143)\n",
            "512. feature: 831, 831 (0.000143)\n",
            "513. feature: 156, 156 (0.000142)\n",
            "514. feature: 154, 154 (0.000142)\n",
            "515. feature: 838, 838 (0.000141)\n",
            "516. feature: 379, 379 (0.000141)\n",
            "517. feature: 199, 199 (0.000140)\n",
            "518. feature: 233, 233 (0.000140)\n",
            "519. feature: 677, 677 (0.000139)\n",
            "520. feature: 106, 106 (0.000138)\n",
            "521. feature: 841, 841 (0.000137)\n",
            "522. feature: 773, 773 (0.000137)\n",
            "523. feature: 128, 128 (0.000136)\n",
            "524. feature: 167, 167 (0.000136)\n",
            "525. feature: 577, 577 (0.000136)\n",
            "526. feature: 766, 766 (0.000136)\n",
            "527. feature: 253, 253 (0.000135)\n",
            "528. feature: 764, 764 (0.000134)\n",
            "529. feature: 69, 69 (0.000134)\n",
            "530. feature: 600, 600 (0.000133)\n",
            "531. feature: 98, 98 (0.000132)\n",
            "532. feature: 770, 770 (0.000132)\n",
            "533. feature: 636, 636 (0.000131)\n",
            "534. feature: 615, 615 (0.000131)\n",
            "535. feature: 673, 673 (0.000131)\n",
            "536. feature: 769, 769 (0.000130)\n",
            "537. feature: 826, 826 (0.000130)\n",
            "538. feature: 250, 250 (0.000130)\n",
            "539. feature: 145, 145 (0.000130)\n",
            "540. feature: 480, 480 (0.000130)\n",
            "541. feature: 342, 342 (0.000130)\n",
            "542. feature: 742, 742 (0.000129)\n",
            "543. feature: 184, 184 (0.000129)\n",
            "544. feature: 594, 594 (0.000129)\n",
            "545. feature: 793, 793 (0.000129)\n",
            "546. feature: 102, 102 (0.000129)\n",
            "547. feature: 808, 808 (0.000129)\n",
            "548. feature: 545, 545 (0.000129)\n",
            "549. feature: 625, 625 (0.000129)\n",
            "550. feature: 780, 780 (0.000128)\n",
            "551. feature: 112, 112 (0.000128)\n",
            "552. feature: 822, 822 (0.000128)\n",
            "553. feature: 681, 681 (0.000128)\n",
            "554. feature: 581, 581 (0.000127)\n",
            "555. feature: 593, 593 (0.000127)\n",
            "556. feature: 813, 813 (0.000127)\n",
            "557. feature: 849, 849 (0.000126)\n",
            "558. feature: 525, 525 (0.000126)\n",
            "559. feature: 803, 803 (0.000126)\n",
            "560. feature: 842, 842 (0.000126)\n",
            "561. feature: 832, 832 (0.000126)\n",
            "562. feature: 223, 223 (0.000126)\n",
            "563. feature: 637, 637 (0.000125)\n",
            "564. feature: 268, 268 (0.000125)\n",
            "565. feature: 607, 607 (0.000125)\n",
            "566. feature: 775, 775 (0.000124)\n",
            "567. feature: 146, 146 (0.000124)\n",
            "568. feature: 486, 486 (0.000124)\n",
            "569. feature: 246, 246 (0.000124)\n",
            "570. feature: 788, 788 (0.000123)\n",
            "571. feature: 736, 736 (0.000123)\n",
            "572. feature: 411, 411 (0.000123)\n",
            "573. feature: 741, 741 (0.000123)\n",
            "574. feature: 802, 802 (0.000122)\n",
            "575. feature: 638, 638 (0.000122)\n",
            "576. feature: 657, 657 (0.000122)\n",
            "577. feature: 134, 134 (0.000122)\n",
            "578. feature: 567, 567 (0.000122)\n",
            "579. feature: 708, 708 (0.000121)\n",
            "580. feature: 229, 229 (0.000120)\n",
            "581. feature: 546, 546 (0.000120)\n",
            "582. feature: 236, 236 (0.000119)\n",
            "583. feature: 823, 823 (0.000118)\n",
            "584. feature: 591, 591 (0.000118)\n",
            "585. feature: 213, 213 (0.000118)\n",
            "586. feature: 606, 606 (0.000117)\n",
            "587. feature: 254, 254 (0.000117)\n",
            "588. feature: 806, 806 (0.000117)\n",
            "589. feature: 538, 538 (0.000116)\n",
            "590. feature: 492, 492 (0.000116)\n",
            "591. feature: 322, 322 (0.000116)\n",
            "592. feature: 679, 679 (0.000116)\n",
            "593. feature: 149, 149 (0.000116)\n",
            "594. feature: 818, 818 (0.000115)\n",
            "595. feature: 539, 539 (0.000115)\n",
            "596. feature: 746, 746 (0.000115)\n",
            "597. feature: 753, 753 (0.000114)\n",
            "598. feature: 542, 542 (0.000114)\n",
            "599. feature: 714, 714 (0.000114)\n",
            "600. feature: 738, 738 (0.000113)\n",
            "601. feature: 650, 650 (0.000113)\n",
            "602. feature: 847, 847 (0.000113)\n",
            "603. feature: 84, 84 (0.000112)\n",
            "604. feature: 203, 203 (0.000112)\n",
            "605. feature: 786, 786 (0.000112)\n",
            "606. feature: 795, 795 (0.000112)\n",
            "607. feature: 547, 547 (0.000112)\n",
            "608. feature: 740, 740 (0.000112)\n",
            "609. feature: 824, 824 (0.000111)\n",
            "610. feature: 739, 739 (0.000111)\n",
            "611. feature: 765, 765 (0.000111)\n",
            "612. feature: 649, 649 (0.000110)\n",
            "613. feature: 595, 595 (0.000110)\n",
            "614. feature: 88, 88 (0.000110)\n",
            "615. feature: 767, 767 (0.000110)\n",
            "616. feature: 153, 153 (0.000109)\n",
            "617. feature: 817, 817 (0.000109)\n",
            "618. feature: 514, 514 (0.000109)\n",
            "619. feature: 271, 271 (0.000108)\n",
            "620. feature: 230, 230 (0.000108)\n",
            "621. feature: 654, 654 (0.000108)\n",
            "622. feature: 416, 416 (0.000108)\n",
            "623. feature: 276, 276 (0.000108)\n",
            "624. feature: 209, 209 (0.000107)\n",
            "625. feature: 503, 503 (0.000107)\n",
            "626. feature: 701, 701 (0.000106)\n",
            "627. feature: 537, 537 (0.000106)\n",
            "628. feature: 845, 845 (0.000106)\n",
            "629. feature: 133, 133 (0.000105)\n",
            "630. feature: 535, 535 (0.000105)\n",
            "631. feature: 807, 807 (0.000105)\n",
            "632. feature: 270, 270 (0.000105)\n",
            "633. feature: 670, 670 (0.000104)\n",
            "634. feature: 260, 260 (0.000104)\n",
            "635. feature: 596, 596 (0.000104)\n",
            "636. feature: 234, 234 (0.000104)\n",
            "637. feature: 544, 544 (0.000104)\n",
            "638. feature: 110, 110 (0.000104)\n",
            "639. feature: 801, 801 (0.000103)\n",
            "640. feature: 674, 674 (0.000103)\n",
            "641. feature: 661, 661 (0.000103)\n",
            "642. feature: 505, 505 (0.000103)\n",
            "643. feature: 829, 829 (0.000103)\n",
            "644. feature: 833, 833 (0.000103)\n",
            "645. feature: 256, 256 (0.000103)\n",
            "646. feature: 239, 239 (0.000103)\n",
            "647. feature: 398, 398 (0.000102)\n",
            "648. feature: 151, 151 (0.000101)\n",
            "649. feature: 217, 217 (0.000101)\n",
            "650. feature: 582, 582 (0.000101)\n",
            "651. feature: 143, 143 (0.000101)\n",
            "652. feature: 771, 771 (0.000101)\n",
            "653. feature: 618, 618 (0.000101)\n",
            "654. feature: 837, 837 (0.000100)\n",
            "655. feature: 732, 732 (0.000100)\n",
            "656. feature: 749, 749 (0.000100)\n",
            "657. feature: 816, 816 (0.000100)\n",
            "658. feature: 175, 175 (0.000099)\n",
            "659. feature: 129, 129 (0.000099)\n",
            "660. feature: 231, 231 (0.000099)\n",
            "661. feature: 610, 610 (0.000099)\n",
            "662. feature: 694, 694 (0.000099)\n",
            "663. feature: 473, 473 (0.000099)\n",
            "664. feature: 141, 141 (0.000098)\n",
            "665. feature: 140, 140 (0.000098)\n",
            "666. feature: 781, 781 (0.000097)\n",
            "667. feature: 255, 255 (0.000097)\n",
            "668. feature: 519, 519 (0.000096)\n",
            "669. feature: 819, 819 (0.000096)\n",
            "670. feature: 791, 791 (0.000096)\n",
            "671. feature: 163, 163 (0.000095)\n",
            "672. feature: 672, 672 (0.000094)\n",
            "673. feature: 431, 431 (0.000093)\n",
            "674. feature: 658, 658 (0.000093)\n",
            "675. feature: 561, 561 (0.000093)\n",
            "676. feature: 796, 796 (0.000092)\n",
            "677. feature: 529, 529 (0.000092)\n",
            "678. feature: 180, 180 (0.000092)\n",
            "679. feature: 716, 716 (0.000092)\n",
            "680. feature: 516, 516 (0.000091)\n",
            "681. feature: 619, 619 (0.000091)\n",
            "682. feature: 166, 166 (0.000091)\n",
            "683. feature: 123, 123 (0.000090)\n",
            "684. feature: 204, 204 (0.000090)\n",
            "685. feature: 812, 812 (0.000090)\n",
            "686. feature: 160, 160 (0.000090)\n",
            "687. feature: 810, 810 (0.000090)\n",
            "688. feature: 830, 830 (0.000089)\n",
            "689. feature: 279, 279 (0.000089)\n",
            "690. feature: 121, 121 (0.000088)\n",
            "691. feature: 161, 161 (0.000088)\n",
            "692. feature: 633, 633 (0.000088)\n",
            "693. feature: 206, 206 (0.000088)\n",
            "694. feature: 820, 820 (0.000088)\n",
            "695. feature: 695, 695 (0.000088)\n",
            "696. feature: 137, 137 (0.000088)\n",
            "697. feature: 836, 836 (0.000087)\n",
            "698. feature: 790, 790 (0.000087)\n",
            "699. feature: 518, 518 (0.000087)\n",
            "700. feature: 821, 821 (0.000086)\n",
            "701. feature: 680, 680 (0.000086)\n",
            "702. feature: 173, 173 (0.000086)\n",
            "703. feature: 811, 811 (0.000086)\n",
            "704. feature: 273, 273 (0.000085)\n",
            "705. feature: 127, 127 (0.000085)\n",
            "706. feature: 117, 117 (0.000085)\n",
            "707. feature: 667, 667 (0.000085)\n",
            "708. feature: 136, 136 (0.000084)\n",
            "709. feature: 178, 178 (0.000084)\n",
            "710. feature: 772, 772 (0.000084)\n",
            "711. feature: 75, 75 (0.000084)\n",
            "712. feature: 125, 125 (0.000084)\n",
            "713. feature: 644, 644 (0.000083)\n",
            "714. feature: 548, 548 (0.000083)\n",
            "715. feature: 243, 243 (0.000083)\n",
            "716. feature: 259, 259 (0.000082)\n",
            "717. feature: 683, 683 (0.000081)\n",
            "718. feature: 559, 559 (0.000081)\n",
            "719. feature: 111, 111 (0.000081)\n",
            "720. feature: 152, 152 (0.000081)\n",
            "721. feature: 645, 645 (0.000081)\n",
            "722. feature: 709, 709 (0.000080)\n",
            "723. feature: 83, 83 (0.000080)\n",
            "724. feature: 735, 735 (0.000080)\n",
            "725. feature: 589, 589 (0.000080)\n",
            "726. feature: 226, 226 (0.000079)\n",
            "727. feature: 214, 214 (0.000079)\n",
            "728. feature: 264, 264 (0.000078)\n",
            "729. feature: 779, 779 (0.000078)\n",
            "730. feature: 705, 705 (0.000078)\n",
            "731. feature: 798, 798 (0.000078)\n",
            "732. feature: 220, 220 (0.000078)\n",
            "733. feature: 70, 70 (0.000077)\n",
            "734. feature: 119, 119 (0.000077)\n",
            "735. feature: 347, 347 (0.000077)\n",
            "736. feature: 269, 269 (0.000076)\n",
            "737. feature: 126, 126 (0.000076)\n",
            "738. feature: 120, 120 (0.000076)\n",
            "739. feature: 113, 113 (0.000075)\n",
            "740. feature: 79, 79 (0.000075)\n",
            "741. feature: 201, 201 (0.000074)\n",
            "742. feature: 205, 205 (0.000074)\n",
            "743. feature: 189, 189 (0.000074)\n",
            "744. feature: 100, 100 (0.000073)\n",
            "745. feature: 186, 186 (0.000073)\n",
            "746. feature: 844, 844 (0.000072)\n",
            "747. feature: 642, 642 (0.000072)\n",
            "748. feature: 195, 195 (0.000072)\n",
            "749. feature: 267, 267 (0.000072)\n",
            "750. feature: 783, 783 (0.000071)\n",
            "751. feature: 196, 196 (0.000071)\n",
            "752. feature: 157, 157 (0.000071)\n",
            "753. feature: 262, 262 (0.000071)\n",
            "754. feature: 663, 663 (0.000071)\n",
            "755. feature: 835, 835 (0.000071)\n",
            "756. feature: 614, 614 (0.000071)\n",
            "757. feature: 543, 543 (0.000070)\n",
            "758. feature: 631, 631 (0.000070)\n",
            "759. feature: 700, 700 (0.000070)\n",
            "760. feature: 210, 210 (0.000070)\n",
            "761. feature: 138, 138 (0.000069)\n",
            "762. feature: 839, 839 (0.000069)\n",
            "763. feature: 198, 198 (0.000069)\n",
            "764. feature: 500, 500 (0.000069)\n",
            "765. feature: 221, 221 (0.000068)\n",
            "766. feature: 706, 706 (0.000068)\n",
            "767. feature: 177, 177 (0.000068)\n",
            "768. feature: 659, 659 (0.000068)\n",
            "769. feature: 785, 785 (0.000068)\n",
            "770. feature: 94, 94 (0.000068)\n",
            "771. feature: 132, 132 (0.000068)\n",
            "772. feature: 261, 261 (0.000067)\n",
            "773. feature: 549, 549 (0.000066)\n",
            "774. feature: 144, 144 (0.000066)\n",
            "775. feature: 109, 109 (0.000064)\n",
            "776. feature: 108, 108 (0.000064)\n",
            "777. feature: 237, 237 (0.000064)\n",
            "778. feature: 114, 114 (0.000064)\n",
            "779. feature: 562, 562 (0.000063)\n",
            "780. feature: 799, 799 (0.000063)\n",
            "781. feature: 212, 212 (0.000063)\n",
            "782. feature: 78, 78 (0.000063)\n",
            "783. feature: 222, 222 (0.000062)\n",
            "784. feature: 238, 238 (0.000062)\n",
            "785. feature: 65, 65 (0.000061)\n",
            "786. feature: 825, 825 (0.000061)\n",
            "787. feature: 168, 168 (0.000061)\n",
            "788. feature: 560, 560 (0.000060)\n",
            "789. feature: 150, 150 (0.000060)\n",
            "790. feature: 557, 557 (0.000060)\n",
            "791. feature: 200, 200 (0.000060)\n",
            "792. feature: 158, 158 (0.000059)\n",
            "793. feature: 148, 148 (0.000059)\n",
            "794. feature: 692, 692 (0.000058)\n",
            "795. feature: 170, 170 (0.000058)\n",
            "796. feature: 215, 215 (0.000058)\n",
            "797. feature: 743, 743 (0.000057)\n",
            "798. feature: 665, 665 (0.000057)\n",
            "799. feature: 675, 675 (0.000056)\n",
            "800. feature: 219, 219 (0.000056)\n",
            "801. feature: 671, 671 (0.000056)\n",
            "802. feature: 227, 227 (0.000055)\n",
            "803. feature: 707, 707 (0.000055)\n",
            "804. feature: 734, 734 (0.000055)\n",
            "805. feature: 92, 92 (0.000054)\n",
            "806. feature: 699, 699 (0.000054)\n",
            "807. feature: 804, 804 (0.000053)\n",
            "808. feature: 697, 697 (0.000053)\n",
            "809. feature: 533, 533 (0.000053)\n",
            "810. feature: 797, 797 (0.000053)\n",
            "811. feature: 235, 235 (0.000052)\n",
            "812. feature: 648, 648 (0.000052)\n",
            "813. feature: 139, 139 (0.000052)\n",
            "814. feature: 774, 774 (0.000051)\n",
            "815. feature: 155, 155 (0.000051)\n",
            "816. feature: 703, 703 (0.000051)\n",
            "817. feature: 172, 172 (0.000049)\n",
            "818. feature: 565, 565 (0.000049)\n",
            "819. feature: 179, 179 (0.000049)\n",
            "820. feature: 244, 244 (0.000048)\n",
            "821. feature: 218, 218 (0.000048)\n",
            "822. feature: 131, 131 (0.000048)\n",
            "823. feature: 169, 169 (0.000048)\n",
            "824. feature: 116, 116 (0.000047)\n",
            "825. feature: 171, 171 (0.000047)\n",
            "826. feature: 124, 124 (0.000046)\n",
            "827. feature: 733, 733 (0.000045)\n",
            "828. feature: 666, 666 (0.000044)\n",
            "829. feature: 187, 187 (0.000043)\n",
            "830. feature: 76, 76 (0.000043)\n",
            "831. feature: 248, 248 (0.000043)\n",
            "832. feature: 118, 118 (0.000042)\n",
            "833. feature: 789, 789 (0.000042)\n",
            "834. feature: 115, 115 (0.000040)\n",
            "835. feature: 185, 185 (0.000040)\n",
            "836. feature: 176, 176 (0.000040)\n",
            "837. feature: 73, 73 (0.000039)\n",
            "838. feature: 105, 105 (0.000039)\n",
            "839. feature: 646, 646 (0.000039)\n",
            "840. feature: 197, 197 (0.000038)\n",
            "841. feature: 183, 183 (0.000038)\n",
            "842. feature: 130, 130 (0.000037)\n",
            "843. feature: 193, 193 (0.000037)\n",
            "844. feature: 188, 188 (0.000036)\n",
            "845. feature: 232, 232 (0.000036)\n",
            "846. feature: 174, 174 (0.000033)\n",
            "847. feature: 192, 192 (0.000031)\n",
            "848. feature: 727, 727 (0.000031)\n",
            "849. feature: 181, 181 (0.000030)\n",
            "850. feature: 164, 164 (0.000029)\n"
          ]
        }
      ],
      "source": [
        "print(\"Feature ranking:\")\n",
        "for f in range(sels.shape[1]):\n",
        "    print(\"%d. feature: %s, %d (%f)\" % (f + 1, sels.columns[indices[f]], indices[f], importances[indices[f]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxxpXJpVxQPS"
      },
      "source": [
        "There isn't too much noise, and none of the features provide nothing for the model. I decided to just keep them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpKpDHJQo_I9"
      },
      "source": [
        "# Model for age of a galaxy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qRZs8CpmyrN"
      },
      "source": [
        "I suspect this one may be difficult. Based on what I know about dust, I'm thinking that I may add it as a feature if the scores need a boost.\n",
        "\n",
        "Maybe the model will be able to recognize that larger amounts of dust can impact the amount of infared light emitted by the galaxy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oMSG7_DnmZnD"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9JHFs1C_pKJJ"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model,scalespec,Age, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "161303TAng3E",
        "outputId": "e08d7d74-b596-4517-a00e-2ba7579c7e53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([23.48521781, 22.97958636, 21.91340041, 23.10194468, 23.180053  ]),\n",
              " 'score_time': array([0.00217319, 0.00284123, 0.00197864, 0.0022347 , 0.00255489]),\n",
              " 'test_score': array([0.57545216, 0.49668981, 0.53288035, 0.47478409, 0.59267523]),\n",
              " 'train_score': array([0.84017538, 0.85800013, 0.85348139, 0.84982387, 0.83948998])}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ap4gVGr53_Ao",
        "outputId": "5d20d353-e95f-48d2-873e-37baae3497fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([23.48521781, 22.97958636, 21.91340041, 23.10194468, 23.180053  ]),\n",
              " 'score_time': array([0.00217319, 0.00284123, 0.00197864, 0.0022347 , 0.00255489]),\n",
              " 'test_score': array([0.57545216, 0.49668981, 0.53288035, 0.47478409, 0.59267523]),\n",
              " 'train_score': array([0.84017538, 0.85800013, 0.85348139, 0.84982387, 0.83948998])}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6MuhpL0ec4N"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9zIhO86Wmr0i"
      },
      "outputs": [],
      "source": [
        "ypred = cross_val_predict(model,spectra, Age, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rohkLh8jpKJe",
        "outputId": "c2d900fa-3583-414c-8836-6e1166332c10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-3.2067787217951267,\n",
              " 1.8387025531684937,\n",
              " -2.3922202548851086,\n",
              " 2.653261020078512)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(Age,ypred, s = 20, c = 'royalblue')\n",
        "plt.xlabel('True Age', fontsize=14)\n",
        "plt.ylabel('Predicted Age',fontsize=14)\n",
        "plt.axis('square')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xedsFluJpS5L",
        "outputId": "efe6b391-4f74-4cbd-d157-b8ef70fb00fe"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(Age,bins=50,density=False,alpha=0.5, label = 'True');\n",
        "plt.hist(ypred,bins=50,density=False,alpha=0.5, color = 'g', label = 'Predicted');\n",
        "plt.legend(fontsize=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhduaEmwiw9h"
      },
      "source": [
        "The model appears to suffer from both high bias and high variance. To begin optimizing, I'll run the same grid search a few times and try to optimize the paramaters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YkWrZ8Wfq7-g"
      },
      "outputs": [],
      "source": [
        "np.random.seed(20)\n",
        "sel = np.random.choice(range(len(ypred)), 500, replace = False) #sample without replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SBKbq7Hsq7-h"
      },
      "outputs": [],
      "source": [
        "sels = spectra.loc[sel,:]\n",
        "selt = Age[sel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lEEiZ6zn-qJD"
      },
      "outputs": [],
      "source": [
        "seld = scaler.fit_transform(sels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2F0nxOU0q7-i"
      },
      "outputs": [],
      "source": [
        "littlescores = cross_validate(model,seld,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rW_kuTFUq7-j",
        "outputId": "092bb6b4-db86-451c-931a-5877805ff9a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5272010284623612, 0.9313391194163391)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udAERKjxsRLw"
      },
      "outputs": [],
      "source": [
        "parameters = {'min_impurity_decrease':[0.1, 0.5, 0.0], \\\n",
        "              'max_features':[750,600,None], 'n_estimators':[75,100,125], 'min_samples_split': [5,2, None]}\n",
        "nmodels = np.product([len(el) for el in parameters.values()])\n",
        "model = GridSearchCV(RandomForestRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
        "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
        "model.fit(seld,selt)\n",
        "\n",
        "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
        "      model.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGUsE1Z_IJ25"
      },
      "source": [
        "##Adding Dust as a feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0T0rE4N88iG"
      },
      "source": [
        "I chose to add dust and see what happens to the model because of how dust can impact the spectra.\n",
        "\n",
        "As explained earlier, dust can impact galaxies by inceasing the appearance of infared light. The light from younger galaxies is fiktered through dust and more of it appears red, much like he light from clearer, older galaxies. I figure, if the model can learn this, maybe it will be able to more accurately predict the age of the galaxies. Higher dust values means the infared light wouldn't necessarily indicate old age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x0Q7Y-Vrsqpt"
      },
      "outputs": [],
      "source": [
        "dustspec = spectra.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6B8EamjfC9T"
      },
      "outputs": [],
      "source": [
        "dustspec['dust'] = DAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B78HC9xatUa7"
      },
      "outputs": [],
      "source": [
        "seld = dustspec.loc[sel,:]\n",
        "selt = Age[sel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K7wx0JJGkU8g"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor(n_estimators=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LM8d9xMXtYss",
        "outputId": "92bd3be0-d427-4b16-e09b-6c32cf2b305b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-42287e87fb66>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlittlescores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseld\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 548, in _validate_data\n    self._check_feature_names(X, reset=reset)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 415, in _check_feature_names\n    feature_names_in = _get_feature_names(X)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1903, in _get_feature_names\n    raise TypeError(\nTypeError: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\n"
          ]
        }
      ],
      "source": [
        "littlescores = cross_validate(model,seld,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PA9ASTScteVC"
      },
      "outputs": [],
      "source": [
        "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYFii2ytVcrc"
      },
      "source": [
        "I saw a little bit of improvement when adding dust as a feature, but the model still could be better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4s0aonAnHtB4"
      },
      "outputs": [],
      "source": [
        "parameters = {'min_impurity_decrease':[0.1, 0.5, 0.0], \\\n",
        "              'max_features':[750,600,None], 'n_estimators':[125,250,500]}\n",
        "nmodels = np.product([len(el) for el in parameters.values()])\n",
        "model = GridSearchCV(GradientBoostingRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
        "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
        "model.fit(seld,selt)\n",
        "\n",
        "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
        "      model.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2xI-eZvnxF6"
      },
      "source": [
        "It looks like the only estimator that helped in the grid search was increasing the number of estimators. Lastly, I'll try to look at the feature importance and see if that's what's causing issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I7RS3ZjGkM7x"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor(n_estimators=500)\n",
        "model.fit(seld,selt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC08XqeLj6ui"
      },
      "outputs": [],
      "source": [
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQThcefcu6V6"
      },
      "outputs": [],
      "source": [
        "print(\"Feature ranking:\")\n",
        "for f in range(seld.shape[1]):\n",
        "    print(\"%d. feature: %s, %d (%f)\" % (f + 1, seld.columns[indices[f]], indices[f], importances[indices[f]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9Ncu3Cv_uOX"
      },
      "source": [
        "The feature importance showed that only 673 features were at all useful in predicting the age, The dust, surprisingly, was very helpful!\n",
        "\n",
        "In order to reduce the range, I tested out a few values in the following loop. I eventually settled on 550 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6mTdaw0uudP"
      },
      "outputs": [],
      "source": [
        "selfeat = pd.DataFrame()\n",
        "for f in range (499):\n",
        "  selfeat[f]=(seld[f])\n",
        "selfeat['550'] = seld['dust']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHFNbGmVv7JP"
      },
      "outputs": [],
      "source": [
        "print(selfeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLMDGKKuwlyJ"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor(n_estimators=1000)\n",
        "scores = cross_validate(model,selfeat,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqUnt_pGw2xF"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldsnUHCtyUHC"
      },
      "outputs": [],
      "source": [
        "scores['test_score'].mean(), scores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjINveurk0V7"
      },
      "outputs": [],
      "source": [
        "ypred = cross_val_predict(model,selfeat, selt, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVI-uvgukzbk"
      },
      "outputs": [],
      "source": [
        "plt.scatter(selt,ypred, s = 20, c = 'royalblue')\n",
        "plt.xlabel('True Age', fontsize=14)\n",
        "plt.ylabel('Predicted Age',fontsize=14)\n",
        "plt.axis('square')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S45pzc7-Z-4"
      },
      "source": [
        "## Using log(Age) in place of the original values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKicsA8n-gLk"
      },
      "outputs": [],
      "source": [
        "LAge = np.log(Age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyuHC7rd-hrV"
      },
      "outputs": [],
      "source": [
        "ypred = cross_val_predict(model,spectra, LAge, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTFrDX8T-v3U"
      },
      "outputs": [],
      "source": [
        "np.random.seed(20)\n",
        "sel = np.random.choice(range(len(ypred)), 500, replace = False) #sample without replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmcnYGJj-4gn"
      },
      "outputs": [],
      "source": [
        "sels = dustspec.loc[sel,:]\n",
        "selt = LAge[sel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHdvmI-lASUt"
      },
      "outputs": [],
      "source": [
        "sels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk5Hz1oN_LtU"
      },
      "outputs": [],
      "source": [
        "sels.columns = sels.columns.astype(str)\n",
        "seld = scaler.fit_transform(sels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MITfIJJo_Py0"
      },
      "outputs": [],
      "source": [
        "littlescores = cross_validate(model,seld,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFF41bHc_Q0x"
      },
      "outputs": [],
      "source": [
        "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q73Q0YipBOM0"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor(n_estimators=1000)\n",
        "scores = cross_validate(model,selfeat,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMFFq9zC4lHx"
      },
      "outputs": [],
      "source": [
        "TAU.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAmGLbyYNsjl"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mojX-JszMEo5"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model,scalespec,TAU, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVi89cr2MEo5"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q64GekWaNAuQ"
      },
      "outputs": [],
      "source": [
        "scores['test_score'].mean(), scores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohu6jqZJMEo7"
      },
      "outputs": [],
      "source": [
        "ypred = cross_val_predict(model,scalespec, Age, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCG0zx7EMEo7"
      },
      "outputs": [],
      "source": [
        "plt.scatter(TAU,ypred, s = 20, c = 'royalblue')\n",
        "plt.xlabel('True TAU', fontsize=14)\n",
        "plt.ylabel('Predicted TAU',fontsize=14)\n",
        "plt.axis('square')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFYV9VVzMEo8"
      },
      "outputs": [],
      "source": [
        "plt.hist(TAU,bins=50,density=False,alpha=0.5, label = 'True');\n",
        "plt.hist(ypred,bins=50,density=False,alpha=0.5, color = 'g', label = 'Predicted');\n",
        "plt.legend(fontsize=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8guYH4ePI7Ni"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfVamPLnISM7"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(model, 'Generalized Learning Curves', scalespec, TAU, train_sizes = np.array([0.05,0.1,0.2,0.5,1.0]), cv = KFold(n_splits=5, shuffle=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0pK1XON5ocd"
      },
      "source": [
        "##Little Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o5kmDqOBl43"
      },
      "outputs": [],
      "source": [
        "sels = spectra.loc[sel,:]\n",
        "selt = TAU[sel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0UGpuDgBl45"
      },
      "outputs": [],
      "source": [
        "seld = scaler.fit_transform(sels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okIReL2rBuq1"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MakI7OW65qZI"
      },
      "outputs": [],
      "source": [
        "littlescores = cross_validate(model,sels,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ6bWgZ3CGhK"
      },
      "outputs": [],
      "source": [
        "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm0TQI1oCVqX"
      },
      "source": [
        "The test scores on a smaller set are significantly worse, which makes me think that this model might require more data than the others.\n",
        "\n",
        "In any case, I'll try a few things to get the scores up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkUBf4H1OniW"
      },
      "source": [
        "##Ridge Regression for TAU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5WtsxVqO71y"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge, Lasso, RidgeCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osrCP6bEO0xQ"
      },
      "outputs": [],
      "source": [
        "MSE = []\n",
        "\n",
        "for alpha in np.logspace(-5,3,9):\n",
        "\n",
        "    #model_reg = Ridge(alpha = alpha, normalize = True)\n",
        "    model_reg = make_pipeline(StandardScaler(with_mean=False), Ridge(alpha=alpha))\n",
        "\n",
        "    scores = cross_validate(model_reg, scalespec, TAU, cv = KFold(n_splits=10, shuffle=True, random_state = 1), scoring = 'neg_mean_squared_error')\n",
        "\n",
        "    print(alpha, (-np.mean(scores['test_score'])))\n",
        "\n",
        "    MSE.append(-np.mean(scores['test_score']))\n",
        "\n",
        "print('Best alpha:', np.logspace(-5,3,9)[np.argmin(MSE)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7weCEv7FwX5"
      },
      "outputs": [],
      "source": [
        "model = Ridge(alpha = 1e-7, normalize = True)\n",
        "\n",
        "model.fit(scalespec,TAU)\n",
        "\n",
        "coef_no_reg =  np.hstack([model.coef_, model.intercept_])\n",
        "\n",
        "print(coef_no_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0F0yhAaFGJC"
      },
      "outputs": [],
      "source": [
        "L1000 = Ridge(alpha = 10, max_iter = 1000000, tol = 0.005, normalize=True)\n",
        "\n",
        "L1000.fit(scalespec, TAU)\n",
        "\n",
        "coef_L1000 =  np.hstack([L1000.coef_, L1000.intercept_])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDRG2NUgFhkX"
      },
      "outputs": [],
      "source": [
        "coef_L1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMPq1zNcGqfN"
      },
      "outputs": [],
      "source": [
        "model = SVC(C=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IGnFXCLHX59"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model,scalespec,TAU, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvBgQFZFHbQ9"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvCiQaYuKjBC"
      },
      "source": [
        "##Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y87JY3C3LJKQ"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor(n_estimators=500)\n",
        "model.fit(scalespec, TAU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUoPp9ORLJKS"
      },
      "outputs": [],
      "source": [
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM9imlzp5ibM"
      },
      "outputs": [],
      "source": [
        "indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okWpv4q-OJ-p"
      },
      "outputs": [],
      "source": [
        "sels = pd.DataFrame(scalespec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEFIBPOvLJKT"
      },
      "outputs": [],
      "source": [
        "print(\"Feature ranking:\")\n",
        "for f in range(sels.shape[1]):\n",
        "    print(\"%d. feature: %s, %d (%f)\" % (f + 1, sels.columns[indices[f]], indices[f], importances[indices[f]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoj3tBv_OzoZ"
      },
      "source": [
        "657\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XK3jBM2QGyI"
      },
      "outputs": [],
      "source": [
        "scalespecdf = pd.DataFrame(scalespec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdPxj94Q3jy5"
      },
      "outputs": [],
      "source": [
        "num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W4n_Tob508J"
      },
      "outputs": [],
      "source": [
        "indices[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELCDzKQoLJKT"
      },
      "outputs": [],
      "source": [
        "selfeat = pd.DataFrame()\n",
        "for f in range (550):\n",
        "  targ = indices[f]\n",
        "  selfeat[f]=(scalespecdf[targ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRNKYiSxLJKU"
      },
      "outputs": [],
      "source": [
        "print(selfeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwO8RHhpOvTq"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor(n_estimators=1000)\n",
        "scores = cross_validate(model,selfeat,TAU, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw2qlMZqOvTq"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUHAvnWAOvTq"
      },
      "outputs": [],
      "source": [
        "scores['test_score'].mean(), scores['train_score'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FclIgwCOB86b"
      },
      "source": [
        "Better train scores, worse test scores. Higher variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGF_CXawSOZP"
      },
      "source": [
        "##Adding Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT2k6RaohyQ5"
      },
      "outputs": [],
      "source": [
        "tauspec = scalespecdf.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEeeA09OhyRE"
      },
      "outputs": [],
      "source": [
        "tauspec['dust'] = DAT\n",
        "tauspec['age'] = Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOeChplMhyRF"
      },
      "outputs": [],
      "source": [
        "scaletau = scaler.fit_transform(tauspec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxF1eWkfjh-Y"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model,tauspec,TAU, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqbHbddOoRdy"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj0NmaSXsNk0"
      },
      "outputs": [],
      "source": [
        "scores['test_score'].mean(), scores['train_score'].mean("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgiy5Me5lvU2"
      },
      "source": [
        "#Sources Used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j46F46TlypW"
      },
      "source": [
        "Dimensionality Reduction - https://stackabuse.com/dimensionality-reduction-in-python-with-scikit-learn/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "p8ZXgF9JW706",
        "WlUZnYGiW-S5",
        "lNn8z_DSmk9_",
        "g25FYfIpkcR-",
        "IpKpDHJQo_I9",
        "w0pK1XON5ocd",
        "zkUBf4H1OniW",
        "bGF_CXawSOZP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}